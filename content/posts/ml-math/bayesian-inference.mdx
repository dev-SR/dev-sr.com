---
title: Introduction to Bayesian inference
description: Explore the fundamental concepts of Bayesian inference, its relevance in machine learning, and its practical applications. Learn how techniques like Markov Chain Monte Carlo (MCMC) and Variational Inference (VI) tackle complex probabilistic problems.
date: '2023-08-28'
tags: [ML Math,Bayesian Inference]
featured: false
---

Bayesian inference is a significant challenge in statistics and various machine learning techniques. Methods like `Gaussian mixture models` for **classification** or `Latent Dirichlet Allocation` for **topic modeling** rely on solving Bayesian inference problems to fit the data.

The tricky part is that *solving Bayesian inference problems can get really tough* depending on how the model is set up – (assumptions, dimensionality, …). **When the problems get big, finding exact solutions becomes incredibly hard, and the computations can become so complex that they're practically impossible**. That's when we turn to **approximation techniques** to create fast and manageable systems.

This post will dive into the two main methods for dealing with the Bayesian inference challenge: `Markov Chain Monte Carlo (MCMC)` and `Variational Inference (VI)`. `MCMC` is all about **sampling** – *it's like randomly checking points to figure out the bigger picture. On the other hand*, `VI` is focused on **approximations** – *it's about making educated guesses to simplify the problem*.

## The Bayesian inference problem

In this section we present the Bayesian inference problem and discuss some computational difficulties before giving the example of Latent Dirichlet Allocation, a concrete machine learning technique of topic modelling in which this problem is encountered.

### What is inference?

**Inference** *is like making educated guesses about things we can't directly see or measure by using information we have that we can see or measure. In short, it is the process of drawing conclusions about unobserved aspects of a population using observed data*. This includes estimating specific values (Punctual Estimations - such as means, medians, proportions, or other parameters), creating ranges of uncertainty (confidence intervals), and approximating distribution characteristics. It's about using available information to make informed judgments about *hidden factors* or causes in a population.

For example, think about weather forecasting. Meteorologists use data like temperature, humidity, and air pressure that they can measure to predict what the weather will be like in the coming days. They're inferring future conditions based on the information they have.

So, inference helps us understand things we can't directly observe by using the information we can observe.

In particular, **Bayesian inference** is a way of *making conclusions based on a mix of prior knowledge and new observations*. Think of it as constantly *updating what you know as you learn new things*. The key is the **Bayes theorem**, which links *what you knew before - before observing any data* (the `prior`), *what you've just seen* (the `likelihood`), and *what you now understand* (the `posterior`).So, the whole idea that rules the Bayesian paradigm is embed in the so called Bayes theorem that expresses the relation between the updated knowledge (the “posterior”), the prior knowledge (the “prior”) and the knowledge coming from the observation (the “likelihood”).

Mathematically , a **prior knowledge**, *modelled by a probability distribution* - such as Beta, Gamma, or Normal distributions - before observing any data, **is updated each time a new observation**, *whose uncertainty is modelled by another probability distribution*, **is recorded.**

A classical example is the **Bayesian inference of parameters**. Imagine you have data `x` that comes from a certain pattern, but you don't know a key parameter (let's call it `θ`) that determines that pattern. You also have some initial guess about what `θ` could be, *represented by a probability distribution : `P(θ)`*. When you get actual data, you can use the Bayes theorem to combine your initial guess (prior) with the new data (likelihood) to get a better, updated understanding of θ (posterior) as follows:

$$
P(\theta\mid x) = \frac{P(x\mid\theta).P(\theta)}{P(x)}
$$

In the equation:

- **$P(\theta)$**: This is your initial guess about the parameter `θ`, expressed as a probability distribution. It's what you think `θ` could be before considering any data.
  - **How do we choose a prior?** Selecting a prior in Bayesian statistics involves choosing a distribution that reflects our beliefs about an unknown parameter. This prior affects the posterior distribution upon incorporating new data. It's crucial to *avoid assigning exact prior probabilities of 0 or 1*, as these would yield unchanged posterior probabilities. This ensures that new evidence can indeed modify our beliefs. Flexible *distribution families* are often used to capture different belief scenarios, enabling customization for specific contexts and updates through Bayesian inference.
    1. **Conjugate Priors:** These priors belong to a family of distributions where the resulting posterior distribution after updating with new evidence remains within the same family. Examples include Beta-Binomial, Gamma-Poisson, and Normal-Normal distributions.
    2. **Non-conjugate Priors:** In cases where suitable conjugate priors are not available, simulation techniques like the Gibbs sampler are used to approximate the posterior distribution.
    3. **Uninformative Priors:** Uninformative priors minimize prior information, allowing the data to strongly influence the posterior. This approach can lead to results similar to frequentist methods, where the focus is on data-driven outcomes.
   In summary, Bayesian analysis involves choosing priors that reflect beliefs, with options ranging from conjugate priors for easy updating, non-conjugate priors using simulation techniques, to uninformative priors emphasizing data influence.

- **$P(x\mid\theta)$**: This is the likelihood, indicating how probable your observed data `x` is, given a certain value of `θ`. It describes the chance of seeing the data if you assume a particular θ.

- **$P(\theta\mid x)$**: This is the posterior, the updated understanding of `θ` after taking into account the observed data. It combines your prior knowledge with the new data to give a better estimate of `θ`.

- **$P(x)$**: This is the evidence, showing how probable it is to observe the specific data `x`. It's a normalization factor that ensures the posterior makes sense in relation to the data.

### Computational difficulties

The Bayes theorem tells us that the computation of the posterior requires three terms: a `prior`, a `likelihood` and an `evidence`. *The first two can be expressed easily as they are part of the assumed model* (in many situation, the prior and the likelihood are explicitly known). However, the third term, that is a normalization factor, requires to be computed such that

$$
p(x) = \int_{\theta}p(x\mid\theta)p(\theta) d\theta
$$

Although in low dimension this integral can be computed without too much difficulties, it can become intractable in higher dimensions. In this last case, the exact computation of the posterior distribution is practically infeasible and some approximation techniques have to be used to get solutions to problems that require to know this posterior (such as mean computation, for example). We can notice that some other computational difficulties can arise from Bayesian inference problem such as, for example, combinatorics problems when some variables are discrete.








